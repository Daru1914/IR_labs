{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70e56cb-00be-49e1-869a-deac83bac346",
   "metadata": {},
   "source": [
    "# Essential skill for the Internet crawling\n",
    "\n",
    "## Regular expressions\n",
    "\n",
    "Regular expressions (aka regex, regexp) are used to search for patterns. Machine-readable languages often have regualar structure (not always), or at least are non-ambiguous.\n",
    "\n",
    "Obvious way is, of course, to let machine parse the document and then process the result (as in the previous lab). But this often result in additinal depenencies and significant memory and time overhead (which is ok for a single document, but won't work for millions).\n",
    "\n",
    "### Simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be93130-a7a5-4f2d-9172-1bccf1d87123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\w+: ['we', 'have', 'only', '5', 'do11ars', 'This', 'amount', 'of', 'is', 'small', 'How', 'should', 'we', 'sur', 'vive']\n",
      "\n",
      "[\\w\\-]+: ['we', 'have', 'only', '5', 'do11ars', 'This', 'amount', 'of', 'is', 'small', 'How', 'should', 'we', 'sur-vive']\n",
      "\n",
      "[a-zA-Z0-9\\-]+: ['we', 'have', 'only', '5', 'do11ars', 'This', 'amount', 'of', 'is', 'small', 'How', 'should', 'we', 'sur-vive']\n",
      "\n",
      ".+: ['we have only 5 do11ars. This amount of $ is small. How should we sur-vive?']\n",
      "\n",
      "[!\\S]+: ['we', 'have', 'only', '5', 'do11ars.', 'This', 'amount', 'of', '$', 'is', 'small.', 'How', 'should', 'we', 'sur-vive?']\n",
      "\n",
      "\\W+[a-z]+\\-[a-z]+.$: [' sur-vive?']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "string = \"we have only 5 do11ars. This amount of $ is small. How should we sur-vive?\"\n",
    "\n",
    "# all alphanumerics\n",
    "pattern = '\\w+'\n",
    "print(pattern, end=\": \")\n",
    "print(re.findall(pattern, string))\n",
    "print()\n",
    "\n",
    "# all alphanumerics but also with hyphen\n",
    "pattern = \"[\\w\\-]+\"\n",
    "print(pattern, end=\": \")\n",
    "print(re.findall(pattern, string))\n",
    "print()\n",
    "\n",
    "# the same but using explicit character enumeration\n",
    "pattern = \"[a-zA-Z0-9\\-]+\"\n",
    "print(pattern, end=\": \")\n",
    "print(re.findall(pattern, string))\n",
    "print()\n",
    "\n",
    "# any symbol\n",
    "pattern = \".+\"\n",
    "print(pattern, end=\": \")\n",
    "print(re.findall(pattern, string))\n",
    "print()\n",
    "\n",
    "# non-spaces, not the same as \\w!\n",
    "pattern = \"[!\\S]+\"\n",
    "print(pattern, end=\": \")\n",
    "print(re.findall(pattern, string))\n",
    "print()\n",
    "\n",
    "\n",
    "# discuss this pattern. Which elements are used here?\n",
    "pattern = \"\\W+[a-z]+\\-[a-z]+.$\"\n",
    "print(pattern, end=\": \")\n",
    "print(re.findall(pattern, string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd60467-c31a-4977-af18-a77862cf60aa",
   "metadata": {},
   "source": [
    "### Find URLs/URIs vs parse the doc\n",
    "\n",
    "Instead of building DOM model and extracting `href` and `src` attributes, you may rely on the structure of the url itself. Extact all URLs from [the page](https://math.stackexchange.com/questions/411486/understanding-the-singular-value-decomposition-svd) with regexp. You major tool is [re.findall(...)](https://docs.python.org/3/library/re.html#). You may also be interested in compiled regular rexpression (if you reuse one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6312c41-143c-4d38-af65-0ad9652caab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "url = \"https://math.stackexchange.com/questions/\"\\\n",
    "        \"411486/understanding-the-singular-value-decomposition-svd\"\n",
    "\n",
    "text = requests.get(url).text\n",
    "\n",
    "# my inspiration - \n",
    "# I took some example URL regexp from the internet, \n",
    "# specifically from here:\n",
    "# https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url\n",
    "expressions = [\n",
    "    \"(?:([A-Za-z]+):)?(\\/{0,3})([0-9.\\-A-Za-z]+)(?::(\\d+))?(?:\\/([^?#]*))?(?:\\?([^#]*))?(?:#(.*))?\",\n",
    "    \"(www|http:|https:)+[^\\s]+[\\w]\",\n",
    "    \"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\",\n",
    "    \"[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)?\",\n",
    "    \"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\n",
    "    \"(?!mailto:)(?:(?:http|https|ftp)://)(?:\\\\S+(?::\\\\S*)?@)?(?:(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[0-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]+-?)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]+-?)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,})))|localhost)(?::\\\\d{2,5})?(?:(/|\\\\?|#)[^\\\\s]*)?\",\n",
    "    \"https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*)\",\n",
    "]\n",
    "\n",
    "for expression in expressions:\n",
    "    print()\n",
    "    pattern = re.compile(expression)\n",
    "    urls = pattern.findall(text)\n",
    "    print(expression)\n",
    "    print(urls[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63197434-4483-4d3c-ae0f-0dfb91f396b7",
   "metadata": {},
   "source": [
    "Was this success? \n",
    "\n",
    "Compose your own minimalistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2055e8c-20d1-4cfe-9229-0f22a24183fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "url = \"https://math.stackexchange.com/questions/\"\\\n",
    "        \"411486/understanding-the-singular-value-decomposition-svd\"\n",
    "\n",
    "text = requests.get(url).text\n",
    "\n",
    "protocol = \"https?://\"\n",
    "domain = \"[\\w\\-\\.]+\"\n",
    "path = \"[/\\w\\-\\.]*\"\n",
    "args =  \n",
    "hashtail = \"(?:#[\\w$%-_;]+)?\"\n",
    "\n",
    "expression = protocol + domain + path + args + hashtail\n",
    "pattern = re.compile(expression)\n",
    "regexp_urls = pattern.findall(text)\n",
    "print(regexp_urls[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10f7aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "string = \"wwwhttps:\"\n",
    "\n",
    "pattern1 = \"(www)(https:): [('www', 'https:')]\"\n",
    "pattern2 = \"(?:www)(?:https:): ['wwwhttps:']\"\n",
    "\n",
    "print(re.findall(pattern1, string))\n",
    "print(re.findall(pattern2, string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2174daf-3ea2-4622-89d2-751aed1e29b9",
   "metadata": {},
   "source": [
    "# Streams and files\n",
    "\n",
    "When you deal with the big files you should take care about the RAM. Today 1GB won't suprise anyone on the desktop, but server machines, which implement crawlers, may be optimized for the resource.\n",
    "\n",
    "Using streams instead of RAM-cached files is a good strategy.\n",
    "\n",
    "- Look for solution here: https://stackoverflow.com/a/16696317\n",
    "- Look for the sample big file here: http://xcal1.vodafone.co.uk/\n",
    "- Read about python memory measurement here: https://pythonspeed.com/articles/measuring-memory-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c819e5ad-2c3e-43b1-a45c-2c1db556e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, psutil, gc \n",
    "\n",
    "def get_mem():\n",
    "    return psutil.Process().memory_info().rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d45cfdf-661e-47bb-a2c1-336b7d091a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_file_url = \"http://212.183.159.230/100MB.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c447d2f-383b-4d5e-ad83-67feab474dec",
   "metadata": {},
   "source": [
    "First, download the file as you would do it simple way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d31dd2-b334-4d77-820e-ed78b81ad5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resident set size: 81137664\n",
      "Resident set size: 185106432\n",
      "Resident set size: 185110528\n",
      "Resident set size: 80248832\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"Resident set size:\", get_mem())\n",
    "data = requests.get(large_file_url).content\n",
    "print(\"Resident set size:\", get_mem())\n",
    "\n",
    "with open('100-RAM', 'wb') as f:\n",
    "    f.write(data)\n",
    "\n",
    "print(\"Resident set size:\", get_mem())\n",
    "data = None\n",
    "gc.collect()\n",
    "print(\"Resident set size:\", get_mem())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad622c-6821-467d-8f9d-6269fed14097",
   "metadata": {},
   "source": [
    "And then use the streaming mode of the `requests` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f20b4eb-a60c-4be1-910e-c029bdf4cb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resident set size: 81121280\n",
      "Resident set size: 81104896\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "def download_file(url, destination):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "gc.collect()\n",
    "print(\"Resident set size:\", get_mem())\n",
    "download_file(large_file_url, \"100-stream\")\n",
    "print(\"Resident set size:\", get_mem())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02814d2-da81-40c6-baa2-a1453626df3a",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "\n",
    "Plain text HTML is a mixture of content, markup, and code. Extracting structure, or URLs, or plain text might be tricky with regular expressions. \n",
    "\n",
    "Building a DOM model is slow, but may save a lot of code and keep you from mistakes.\n",
    "\n",
    "## Extract all sentences\n",
    "For indexing and semantic analysis we use different granularity. Often sentence is a good choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d47dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186a793c-39ea-463d-8106-b719e4de3e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thanks for your comment.', 'I read what are singular values in the D matrix.', 'I know they are square roots of eigenvalues of $\\\\textbf{A}^{\\\\textrm{T}}\\\\textbf{A}$.', \"What I don't understand is the meaning?\", 'I know if I e.g.', 'take covariance matrix and diagonalize it, I end up with eigenvalues (or maximum/unique/?singular?', 'values) in a diagonal matrix representing variances.', 'SVD however is product of three matrices: outer product o, singular values, inner product of A.', \"But I still don't see the meaning of all this.\", '$\\\\endgroup$']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from nltk import tokenize\n",
    "\n",
    "doc_url = \"https://math.stackexchange.com/questions/\"\\\n",
    "        \"411486/understanding-the-singular-value-decomposition-svd\"\n",
    "\n",
    "text = requests.get(doc_url).text\n",
    "dom = BeautifulSoup(text)\n",
    "paragraphs = [p.strip() for p in dom.text.split('\\n') if p.strip()]\n",
    "\n",
    "sents = []\n",
    "for p in paragraphs:\n",
    "    sents.extend(tokenize.sent_tokenize(p))\n",
    "    \n",
    "print(sents[90:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead20dc-0608-4dde-a34a-3663692c9c6c",
   "metadata": {},
   "source": [
    "# Extract URLs from nodes\n",
    "\n",
    "Be careful with relative links. How would you process them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33586e48-d334-4641-9d37-a24894026b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://math.stackexchange.com/users/login?ssrc=question_page&returnurl=https%3a%2f%2fmath.stackexchange.com%2fquestions%2f411486',\n",
       " 'https://worldbuilding.stackexchange.com/questions/241334/if-humans-had-no-access-to-gunpowder-what-else-would-they-use-to-power-guns',\n",
       " 'https://math.stackexchange.com/posts/3283853/timeline',\n",
       " 'https://i.stack.imgur.com/FxZ1Z.png',\n",
       " 'https://math.stackexchange.com/users/581561/tomasz-bartkowiak',\n",
       " 'https://math.stackexchange.com/posts/411486/revisions',\n",
       " 'https://math.stackexchange.com/questions/3982996/singular-value-decomposition-for-unitary-matrices',\n",
       " 'https://stackoverflowteams.com/teams/create/free?utm_source=so-owned&utm_medium=side-bar&utm_campaign=campaign-38&utm_content=cta',\n",
       " 'https://ell.stackexchange.com/questions/331957/what-is-the-word-with-a-negative-meaning-that-expresses-a-man-who-talks-as-if-he',\n",
       " 'https://math.stackexchange.com/users/35472/mhenni-benghorbal']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.parse as pars\n",
    "\n",
    "all_hrefs = dom.find_all('a', href=True)\n",
    "all_urls = set()\n",
    "\n",
    "for a in all_hrefs:\n",
    "    url = a['href']\n",
    "    url = pars.urljoin(doc_url, url)\n",
    "    all_urls.add(url)\n",
    "\n",
    "all_urls = list(all_urls)\n",
    "all_urls[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9951d22-ec99-4d13-ad47-38d35d388827",
   "metadata": {},
   "source": [
    "Discuss the next result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec65f900-3a74-4664-8b38-301f7c292649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|DOM ∩ REGX| = 50\n",
      "|DOM \\ REGX| = 90\n",
      "|REGX \\ DOM| = 71\n"
     ]
    }
   ],
   "source": [
    "print(\"|DOM ∩ REGX| =\", len(set(all_urls) & set(regexp_urls)))\n",
    "print(\"|DOM \\ REGX| =\", len(set(all_urls) - set(regexp_urls)))\n",
    "print(\"|REGX \\ DOM| =\", len(set(regexp_urls) - set(all_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6bb8ed-9a9b-44db-bb97-9ef6cfe69b97",
   "metadata": {},
   "source": [
    "# Unique file name\n",
    "\n",
    "Please, never try to convert a domain (`google.com`), or a path component (`/index.php`) into a filename. They are not unique!\n",
    "\n",
    "Also, better not to try to substitute sensitive symbols of the full URL (`/:`...) -- you will definitely forget one. Also, you may easily overflow file name.\n",
    "\n",
    "Nice way is to use hash strings with fixed length and character set. Compute hash strings from the previous list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83ab186e-d4e0-4612-a4f4-be7eadae4d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e9f43c65ec43044149129b80c662345a https://math.st...stions%2f411486\n",
      "6de9be38c69b5902a111ac746f1a6f0f https://worldbu...e-to-power-guns\n",
      "4d59e844a8778cf848afa088e3386cb0 https://math.st...283853/timeline\n",
      "68ae095c17ce08432ef0b33f3c9990d5 https://i.stack...r.com/FxZ1Z.png\n",
      "24497ea9000c3d03dc5e7d4856d30b22 https://math.st...masz-bartkowiak\n",
      "d5c9e0b673687b77594f8534026dd443 https://math.st...11486/revisions\n",
      "b815bd45d0e7db79887555804bb02498 https://math.st...nitary-matrices\n",
      "0d20bf02f04c6d8fe5138b7430abba43 https://stackov...utm_content=cta\n",
      "187cc6eca2e4f36c81702905f345ac96 https://ell.sta...-talks-as-if-he\n",
      "afd6828d57d7abd4fab746a6e76a5460 https://math.st...enni-benghorbal\n",
      "c2e70e5826e387811ad4b8801d06acc1 https://www.ins...hestackoverflow\n",
      "13b384643f6fa46dd79a702dfecaf2ca https://stackex...estions?tab=hot\n",
      "60d7df84db61a7d20901e2604fda9252 https://stackov...rflow.com/legal\n",
      "f0e85729294a81aecdc44eb0136e5662 https://rpg.sta...tside-of-a-turn\n",
      "3c61a0e10353ba5825baa95bc2a60039 https://math.st...456431/timeline\n",
      "dfd5d645d0e66381db5e142ba5a1ad76 https://stackov...erms-of-service\n",
      "be51bce35e737525c81bd5e5dc530d63 https://math.st...e.com/a/3456462\n",
      "5d512b0c74ba1d1164261abf56a0b532 https://outdoor...gdown-allergies\n",
      "618e899b7604695c6e1a4c29d1366295 https://math.st...953/ittay-weiss\n",
      "5e724c737aef37f123f3c3e3dc7e64a8 https://math.st...rigo-de-azevedo\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "for url in all_urls[:20]:\n",
    "    s = hashlib.md5(url.encode(\"utf-8\")).hexdigest()\n",
    "    print(s, url[:15] + \"...\" + url[-15:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
