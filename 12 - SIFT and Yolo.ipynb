{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Image search using [SIFT](https://www.thepythoncode.com/article/sift-feature-extraction-using-opencv-in-python)\n",
    "\n",
    "Let's think about information retrieval in the context of image search. How can we find images similar to a query in a fast way (faster than doing pair-wise comparison with all images in a database)? How can we identify same objects taken in slightly different contexts? \n",
    "\n",
    "One way to do this is to find special points of interest in every image, so called keypoints (or descriptors), which characterize the image and which are more or less invariant to scaling, orientation, illumination changes, and some other distortions. There are several algorithms available that identify such keypoints, and today we will focus on [SIFT](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform). \n",
    "\n",
    "Your task is to apply SIFT to a dataset of images and enable similar images search.\n",
    "\n",
    "## Get dataset\n",
    "\n",
    "We will use `Caltech 101` dataset, download it from [here](https://data.caltech.edu/records/mzrjq-6wc02). It consists of pictures of objects belonging to 101 categories. About 40 to 800 images per category. Most categories have about 50 images. The size of each image is roughly 300 x 200 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT example\n",
    "\n",
    "Below is the example of SIFT keyponts extraction using `opencv`. [This](https://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html) is a dedicated tutorial, and [this](https://docs.opencv.org/master/dc/dc3/tutorial_py_matcher.html) is another tutorial you may need to find matches between two images (use in your code `cv.drawMatches()` function to display keypoint matches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "     --------------------------------------- 38.2/38.2 MB 16.0 MB/s eta 0:00:00\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.7.0.72-cp37-abi3-win_amd64.whl (44.9 MB)\n",
      "     ---------------------------------------- 44.9/44.9 MB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.23.4)\n",
      "Installing collected packages: opencv-python, opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.7.0.72 opencv-python-4.7.0.72\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.23.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python opencv-contrib-python\n",
    "# or use https://huggingface.co/datasets/will33am/Caltech101\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find a dataset script at c:\\Users\\user\\Documents\\githubWorkspace\\3rd_year_2\\IR_Labs\\12\\will33am\\Caltech101\\Caltech101.py or any data file in the same directory. Couldn't find 'will33am/Caltech101' on the Hugging Face Hub either: FileNotFoundError: Dataset 'will33am/Caltech101' doesn't exist on the Hub. If the repo is private or gated, make sure to log in with `huggingface-cli login`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\githubWorkspace\\3rd_year_2\\IR_Labs\\12\\12 - SIFT and Yolo.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/githubWorkspace/3rd_year_2/IR_Labs/12/12%20-%20SIFT%20and%20Yolo.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/githubWorkspace/3rd_year_2/IR_Labs/12/12%20-%20SIFT%20and%20Yolo.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mwill33am/Caltech101\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/githubWorkspace/3rd_year_2/IR_Labs/12/12%20-%20SIFT%20and%20Yolo.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ds \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mwill33am/Caltech101\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1759\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, **config_kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[0;32m   1755\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[0;32m   1756\u001b[0m )\n\u001b[0;32m   1758\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 1759\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   1760\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[0;32m   1761\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1762\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   1763\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   1764\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1765\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m   1766\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   1767\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   1768\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1769\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   1770\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[0;32m   1771\u001b[0m )\n\u001b[0;32m   1773\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1496\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1495\u001b[0m     download_config\u001b[39m.\u001b[39muse_auth_token \u001b[39m=\u001b[39m use_auth_token\n\u001b[1;32m-> 1496\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   1497\u001b[0m     path,\n\u001b[0;32m   1498\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1499\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   1500\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   1501\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   1502\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   1503\u001b[0m )\n\u001b[0;32m   1505\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m builder_cls \u001b[39m=\u001b[39m import_main_class(dataset_module\u001b[39m.\u001b[39mmodule_path)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1214\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1213\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, \u001b[39mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m-> 1214\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1215\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1216\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hugging Face Hub either: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e1)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1218\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1219\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find a dataset script at c:\\Users\\user\\Documents\\githubWorkspace\\3rd_year_2\\IR_Labs\\12\\will33am\\Caltech101\\Caltech101.py or any data file in the same directory. Couldn't find 'will33am/Caltech101' on the Hugging Face Hub either: FileNotFoundError: Dataset 'will33am/Caltech101' doesn't exist on the Hub. If the repo is private or gated, make sure to log in with `huggingface-cli login`."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "load_dataset(\"will33am/Caltech101\")\n",
    "ds = load_dataset(\"will33am/Caltech101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = ds['test'], ds['train']\n",
    "\n",
    "CLASSES = sorted(list(set([row['label'] for row in train])))\n",
    "print(CLASSES)\n",
    "\n",
    "strawberries = [row for row in train if row['label'] == 'strawberry']\n",
    "wrenches = [row for row in train if row['label'] == 'wrench']\n",
    "wrenches[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# img_dir = '../../101_ObjectCategories'\n",
    "img = np.array(wrenches[17]['image'])\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# older versions of OpenCV\n",
    "# sift = cv.xfeatures2d.SIFT_create()\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "kp = sift.detect(gray, None)\n",
    "# use detectAndCompute(...) to get descriptors themselves\n",
    "\n",
    "print(f\"1st keypoint Location ({kp[0].pt[0]:.2f}, {kp[0].pt[1]:.2f})\")\n",
    "print(f\"1st keypoint Radius: {kp[0].size};  angle:{kp[0].angle}\")\n",
    "img=cv.drawKeypoints(gray, kp, img, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "**Q**: Discuss what you see here. What is the meaning of circle diameter? Of the angle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index of keypoints\n",
    "\n",
    "Let's suppose we've found image descriptors. How do we find similar images, having this information? In our case the descriptors are 128-dinensional vectors per keypoint, and there can be hundreds of such points. To enable fast search of similar images, you will index descriptors of all images using some data structure for approximate nearest neighbors search, such as Navigable Small World or Annoy. Then, for a (new) query image you will generate descriptors, and for each of these descriptors you will find its nearest neighbors (using Euclidean or Cosine distance, which you prefer). Finally, you will sort potential similar images (retrieved from neighbor descriptors) by frequency with which they appear in the nearest neighbors (more matches - higher the rank).\n",
    "\n",
    "### Build an index\n",
    "\n",
    "Read all images, saving category information. For every image generate SIFT descriptors and index them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all images and add their descriptors to index\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_sift_descriptors(img):    \n",
    "\n",
    "    # TODO return keypoints and their descriptors\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return kp, des\n",
    "        \n",
    "\n",
    "def get_top_descriptors(kp, des, top_k):\n",
    "    response_sort_indices = [i for (v, i) in sorted(((v, i) for (i, v) in enumerate(kp)), \n",
    "                                       key=lambda k: k[0].response, reverse=True)]        \n",
    "    top_des = np.take(des, response_sort_indices[:top_k], axis=0)\n",
    "    return top_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "kp, des = generate_sift_descriptors(wrenches[3]['image'])\n",
    "print(\"Keypoints:\", len(kp), len(des))\n",
    "print(\"Center:\", kp[4].pt)\n",
    "print(\"Vector:\\n\", des[4].reshape(16, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "dataset = train\n",
    "categories = list(set([row['label'] for row in dataset]))\n",
    "cat_lookup = dict((c, i) for i, c in enumerate(categories))\n",
    "\n",
    "for i, row in enumerate(tqdm(train)):\n",
    "    idn, img, label = row['id'], row['image'], row['label'] \n",
    "    keypoints, descriptors = generate_sift_descriptors(img)\n",
    "    vectors.append(get_top_descriptors(keypoints, descriptors, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "annoy = AnnoyIndex(128, 'euclidean')\n",
    "for i, vectors32 in enumerate(vectors):\n",
    "    for vec in vectors32:\n",
    "        annoy.add_item(i, vec)\n",
    "\n",
    "annoy.build(100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement search function\n",
    "\n",
    "Implement a function which returns `k` besr matching classes (names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def classifier(image, index, k):\n",
    "    keypoints, descriptors = generate_sift_descriptors(image)\n",
    "    vecs = get_top_descriptors(keypoints, descriptors, 32)\n",
    "    \n",
    "    # TODO:\n",
    "    # return the list of ordered pairs,\n",
    "    # contaning similarity and class name\n",
    "    \n",
    "    return counter.most_common(k)\n",
    "\n",
    "\n",
    "\n",
    "print(\"STRAWBERRY\")\n",
    "result = classifier(strawberries[22]['image'], annoy, 10)\n",
    "print(*result, sep='\\n')\n",
    "print()\n",
    "print(\"WRENCH\")\n",
    "result = classifier(wrenches[11]['image'], annoy, 10)\n",
    "print(*result, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Before going further, discuss, why SIFT is unsuitable for searching similar things. What is the application area? Is it reliable in this area, and to which extent?\n",
    "\n",
    "\n",
    "# 2. Deep classifiers and Embeddings\n",
    "\n",
    "Based on:\n",
    "- https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "- https://github.com/christiansafka/img2vec\n",
    "- https://github.com/ultralytics/yolov5\n",
    "\n",
    "### Obtain a single label for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "\n",
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Ferry_in_Istanbul_01.JPG/1200px-Ferry_in_Istanbul_01.JPG'\n",
    "im = imread(url)\n",
    "results = model(im)\n",
    "pandas_detections_df = results.pandas().xyxy[0]\n",
    "pandas_detections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the classes for the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i, row in enumerate(dataset):\n",
    "    if i % 213 != 0: continue\n",
    "    results = model(row['image'])\n",
    "    tag = results.pandas().xyxy[0]['name']\n",
    "    tag = tag[0] if len(tag) else None\n",
    "    cat = row['label']\n",
    "    print(f\"{cat}\\t{tag}\")\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.imshow(np.array(row['image']))\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss:** \n",
    "- Look at the results. \n",
    "- Can we use this for retrieval in the same way as we used SIFT features? \n",
    "- What if the labels are different from original? What if there are multiple or no labels?\n",
    "\n",
    "## Vector embedding for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install img2vec_pytorch Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "\n",
    "url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Ferry_in_Istanbul_01.JPG/1200px-Ferry_in_Istanbul_01.JPG'\n",
    "img = imread(url)\n",
    "\n",
    "# Initialize Img2Vec\n",
    "img2vec = Img2Vec(cuda=False)\n",
    "# some magic with broken Pillow.\n",
    "vector = img2vec.get_vec([Image.fromarray(img)]).reshape(-1)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = []\n",
    "\n",
    "def get_vectors(images):\n",
    "\n",
    "    # TODO\n",
    "    # return the np.array with the shape of (files x 512)\n",
    "\n",
    "    # some magic with broken pillow\n",
    "    # this should work: img2vec.get_vec([Image.fromarray(np.array(image))])\n",
    "    \n",
    "    return ...\n",
    "\n",
    "sorted_dataset = map(int, np.argsort([row['label'] for row in dataset]))\n",
    "images_sample = [dataset[row]['image'] for i, row in enumerate(sorted_dataset) if i < 200]\n",
    "embedding_vectors = get_vectors(images_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "d = pairwise_distances(embedding_vectors, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(d, cmap='RdBu', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
